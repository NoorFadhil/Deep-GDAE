{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate our corpus to train the Base Model for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#pip install -U gensim\n",
    "from gensim.models import word2vec\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embSize = 200\n",
    "pos_file = \"data/dataset_disgent_ctd_6719.csv\"\n",
    "neg_file=\"data/negatives_5000.csv\"\n",
    "ftrain=\"../data/our_corpus/train_samples_50of100.csv\"\n",
    "ftest=\"../data/our_corpus/test_samples_20of100.csv\"\n",
    "fval=\"../data/our_corpus/val_samples_30of100.csv\"\n",
    "# Replace with path of word embdding file   \n",
    "wefile = \"/suport/PubMed-and-PMC-w2v.bin\"\n",
    "train_frac=0.5\n",
    "test_frac=0.2\n",
    "val_frac=0.3\n",
    "random_seed=1331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples= pd.read_csv(neg_file, encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample postive and negative ,  and then combine& shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NofPmids</th>\n",
       "      <th>NofSnps</th>\n",
       "      <th>associationType</th>\n",
       "      <th>diseaseId</th>\n",
       "      <th>diseaseName</th>\n",
       "      <th>diseaseType</th>\n",
       "      <th>disease_mention</th>\n",
       "      <th>geneId</th>\n",
       "      <th>geneSymbol</th>\n",
       "      <th>gene_mention</th>\n",
       "      <th>originalSource</th>\n",
       "      <th>pmid</th>\n",
       "      <th>raw_sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C2239176</td>\n",
       "      <td>Liver carcinoma</td>\n",
       "      <td>disease</td>\n",
       "      <td>hepatocellular carcinomas</td>\n",
       "      <td>406906</td>\n",
       "      <td>MIR122</td>\n",
       "      <td>miR-122</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>16924677</td>\n",
       "      <td>Downregulation of miR-122 in the rodent and hu...</td>\n",
       "      <td>0.231825</td>\n",
       "      <td>Downregulation of &lt;span class=\"gene\" id=\"16924...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C0015695</td>\n",
       "      <td>Fatty Liver</td>\n",
       "      <td>disease</td>\n",
       "      <td>hepatic steatosis</td>\n",
       "      <td>8856</td>\n",
       "      <td>NR1I2</td>\n",
       "      <td>PXR</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>25182422</td>\n",
       "      <td>In mice, both ligand-dependent activation and ...</td>\n",
       "      <td>0.200549</td>\n",
       "      <td>In mice, both ligand-dependent activation and ...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C0003873</td>\n",
       "      <td>Rheumatoid Arthritis</td>\n",
       "      <td>disease</td>\n",
       "      <td>RA</td>\n",
       "      <td>3239</td>\n",
       "      <td>HOXD13</td>\n",
       "      <td>HOXD13</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>17568789</td>\n",
       "      <td>HOXD10, HOXD11, HOXD13, CCL8 and LIM homeobox ...</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>HOXD10, HOXD11, &lt;span class=\"gene\" id=\"1756878...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Therapeutic</td>\n",
       "      <td>C0009375</td>\n",
       "      <td>Colonic Neoplasms</td>\n",
       "      <td>group</td>\n",
       "      <td>colon tumors</td>\n",
       "      <td>11156</td>\n",
       "      <td>PTP4A3</td>\n",
       "      <td>Ptp4a3</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>23555575</td>\n",
       "      <td>Ptp4a3-null mice developed 50% fewer colon tum...</td>\n",
       "      <td>0.200549</td>\n",
       "      <td>&lt;span class=\"gene\" id=\"23555575-10-0-6\"&gt;Ptp4a3...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Therapeutic</td>\n",
       "      <td>C0424295</td>\n",
       "      <td>Hyperactive behavior</td>\n",
       "      <td>phenotype</td>\n",
       "      <td>hyperactivity</td>\n",
       "      <td>885</td>\n",
       "      <td>CCK</td>\n",
       "      <td>CCK-8</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>3561887</td>\n",
       "      <td>Local treatment with the opioid antagonist nal...</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>Local treatment with the opioid antagonist nal...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C0030305</td>\n",
       "      <td>Pancreatitis</td>\n",
       "      <td>disease</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>9075</td>\n",
       "      <td>CLDN2</td>\n",
       "      <td>CLDN2</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>23143602</td>\n",
       "      <td>Common genetic variants in the CLDN2 and PRSS1...</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>Common genetic variants in the &lt;span class=\"ge...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C0001430</td>\n",
       "      <td>Adenoma</td>\n",
       "      <td>group</td>\n",
       "      <td>adenomas</td>\n",
       "      <td>476</td>\n",
       "      <td>ATP1A1</td>\n",
       "      <td>ATP1A1</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>23416519</td>\n",
       "      <td>Somatic mutations in ATP1A1 and ATP2B3 lead to...</td>\n",
       "      <td>0.200824</td>\n",
       "      <td>Somatic mutations in &lt;span class=\"gene\" id=\"23...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C0009404</td>\n",
       "      <td>Colorectal Neoplasms</td>\n",
       "      <td>group</td>\n",
       "      <td>colorectal tumors</td>\n",
       "      <td>7849</td>\n",
       "      <td>PAX8</td>\n",
       "      <td>PAX8</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>26075790</td>\n",
       "      <td>We identified significant expression quantitat...</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>We identified significant expression quantitat...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C0007131</td>\n",
       "      <td>Non-Small Cell Lung Carcinoma</td>\n",
       "      <td>disease</td>\n",
       "      <td>NSCLC</td>\n",
       "      <td>27436</td>\n",
       "      <td>EML4</td>\n",
       "      <td>EML4</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>22617245</td>\n",
       "      <td>We selected NSCLC cell lines--A549 (KRAS G12S)...</td>\n",
       "      <td>0.236264</td>\n",
       "      <td>We selected &lt;span class=\"disease\" id=\"22617245...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomarker</td>\n",
       "      <td>C2239176</td>\n",
       "      <td>Liver carcinoma</td>\n",
       "      <td>disease</td>\n",
       "      <td>hepatocellular carcinoma</td>\n",
       "      <td>2305</td>\n",
       "      <td>FOXM1</td>\n",
       "      <td>FoxM1</td>\n",
       "      <td>CTD_human</td>\n",
       "      <td>17173139</td>\n",
       "      <td>A cell-penetrating ARF peptide inhibitor of Fo...</td>\n",
       "      <td>0.286593</td>\n",
       "      <td>A cell-penetrating ARF peptide inhibitor of &lt;s...</td>\n",
       "      <td>CTD_human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NofPmids  NofSnps associationType diseaseId  \\\n",
       "3264         1        0       Biomarker  C2239176   \n",
       "6472         1        0       Biomarker  C0015695   \n",
       "2383         1        0       Biomarker  C0003873   \n",
       "253          1        0     Therapeutic  C0009375   \n",
       "6467         2        0     Therapeutic  C0424295   \n",
       "...        ...      ...             ...       ...   \n",
       "6528         1        0       Biomarker  C0030305   \n",
       "3665         2        0       Biomarker  C0001430   \n",
       "6121         1        0       Biomarker  C0009404   \n",
       "2024         6        0       Biomarker  C0007131   \n",
       "1548         2        0       Biomarker  C2239176   \n",
       "\n",
       "                        diseaseName diseaseType            disease_mention  \\\n",
       "3264                Liver carcinoma     disease  hepatocellular carcinomas   \n",
       "6472                    Fatty Liver     disease          hepatic steatosis   \n",
       "2383           Rheumatoid Arthritis     disease                         RA   \n",
       "253               Colonic Neoplasms       group               colon tumors   \n",
       "6467           Hyperactive behavior   phenotype              hyperactivity   \n",
       "...                             ...         ...                        ...   \n",
       "6528                   Pancreatitis     disease               pancreatitis   \n",
       "3665                        Adenoma       group                   adenomas   \n",
       "6121           Colorectal Neoplasms       group          colorectal tumors   \n",
       "2024  Non-Small Cell Lung Carcinoma     disease                      NSCLC   \n",
       "1548                Liver carcinoma     disease   hepatocellular carcinoma   \n",
       "\n",
       "      geneId geneSymbol gene_mention originalSource      pmid  \\\n",
       "3264  406906     MIR122      miR-122      CTD_human  16924677   \n",
       "6472    8856      NR1I2          PXR      CTD_human  25182422   \n",
       "2383    3239     HOXD13       HOXD13      CTD_human  17568789   \n",
       "253    11156     PTP4A3       Ptp4a3      CTD_human  23555575   \n",
       "6467     885        CCK        CCK-8      CTD_human   3561887   \n",
       "...      ...        ...          ...            ...       ...   \n",
       "6528    9075      CLDN2        CLDN2      CTD_human  23143602   \n",
       "3665     476     ATP1A1       ATP1A1      CTD_human  23416519   \n",
       "6121    7849       PAX8         PAX8      CTD_human  26075790   \n",
       "2024   27436       EML4         EML4      CTD_human  22617245   \n",
       "1548    2305      FOXM1        FoxM1      CTD_human  17173139   \n",
       "\n",
       "                                           raw_sentence     score  \\\n",
       "3264  Downregulation of miR-122 in the rodent and hu...  0.231825   \n",
       "6472  In mice, both ligand-dependent activation and ...  0.200549   \n",
       "2383  HOXD10, HOXD11, HOXD13, CCL8 and LIM homeobox ...  0.200275   \n",
       "253   Ptp4a3-null mice developed 50% fewer colon tum...  0.200549   \n",
       "6467  Local treatment with the opioid antagonist nal...  0.200275   \n",
       "...                                                 ...       ...   \n",
       "6528  Common genetic variants in the CLDN2 and PRSS1...  0.200275   \n",
       "3665  Somatic mutations in ATP1A1 and ATP2B3 lead to...  0.200824   \n",
       "6121  We identified significant expression quantitat...  0.200275   \n",
       "2024  We selected NSCLC cell lines--A549 (KRAS G12S)...  0.236264   \n",
       "1548  A cell-penetrating ARF peptide inhibitor of Fo...  0.286593   \n",
       "\n",
       "                                               sentence     source  \n",
       "3264  Downregulation of <span class=\"gene\" id=\"16924...  CTD_human  \n",
       "6472  In mice, both ligand-dependent activation and ...  CTD_human  \n",
       "2383  HOXD10, HOXD11, <span class=\"gene\" id=\"1756878...  CTD_human  \n",
       "253   <span class=\"gene\" id=\"23555575-10-0-6\">Ptp4a3...  CTD_human  \n",
       "6467  Local treatment with the opioid antagonist nal...  CTD_human  \n",
       "...                                                 ...        ...  \n",
       "6528  Common genetic variants in the <span class=\"ge...  CTD_human  \n",
       "3665  Somatic mutations in <span class=\"gene\" id=\"23...  CTD_human  \n",
       "6121  We identified significant expression quantitat...  CTD_human  \n",
       "2024  We selected <span class=\"disease\" id=\"22617245...  CTD_human  \n",
       "1548  A cell-penetrating ARF peptide inhibitor of <s...  CTD_human  \n",
       "\n",
       "[2000 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change random seed to sample different data in each run \n",
    "positive_samples,negative_samples=sample_positive_negative(pos_file,neg_file,neg_ratio= 1,num_pos_samples= 4000,random_seed=random_seed)\n",
    "\n",
    "pos_train_samples,pos_test_samples,pos_val_samples=split_train_test_val(positive_samples,train_frac,test_frac,val_frac,random_seed)\n",
    "\n",
    "neg_train_samples,neg_test_samples,neg_val_samples=split_train_test_val(negative_samples,train_frac,test_frac,val_frac,random_seed)\n",
    "\n",
    "pos_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine\n",
    "train_samples=pos_train_samples.append(neg_train_samples,sort=False)  \n",
    "#shuffle\n",
    "train_samples=train_samples.sample(frac=1,random_state=random_seed)\n",
    "\n",
    "#combine\n",
    "test_samples=pos_test_samples.append(neg_test_samples,sort=False)  \n",
    "#shuffle\n",
    "test_samples=test_samples.sample(frac=1,random_state=random_seed)\n",
    "\n",
    "#combine\n",
    "val_samples=pos_val_samples.append(neg_val_samples,sort=False)  \n",
    "#shuffle\n",
    "val_samples=val_samples.sample(frac=1,random_state=random_seed)\n",
    "\n",
    "train_samples.to_csv(ftrain,index=None)\n",
    "test_samples.to_csv(ftest,index=None)\n",
    "val_samples.to_csv(fval,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read  Data  and Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input File Reading\n",
      "Input File Reading\n",
      "Input File Reading\n"
     ]
    }
   ],
   "source": [
    "Tr_sent_contents, Tr_entity1_list, Tr_entity2_list, Tr_sent_lables,Tr_gene_id_list,Tr_disease_id_list = dataRead(ftrain,max_length=100 )\n",
    "\n",
    "Tr_word_list, Tr_d1_list, Tr_d2_list  = get_wordList_and_distances_Corpus(Tr_sent_contents, Tr_entity1_list, Tr_entity2_list)\n",
    "\n",
    "V_sent_contents, V_entity1_list, V_entity2_list, V_sent_lables, V_gene_id_list,V_disease_id_list = dataRead(fval,max_length=100 )\n",
    "\n",
    "V_word_list, V_d1_list, V_d2_list  = get_wordList_and_distances_Corpus(V_sent_contents, V_entity1_list, V_entity2_list)\n",
    "\n",
    "Te_sent_contents, Te_entity1_list, Te_entity2_list, Te_sent_lables,Te_gene_id_list,Te_disease_id_list = dataRead(ftest,max_length=100 )\n",
    "\n",
    "Te_word_list, Te_d1_list, Te_d2_list  = get_wordList_and_distances_Corpus(Te_sent_contents, Te_entity1_list, Te_entity2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size 3997\n",
      "val_size 2398\n",
      "test_size 1597\n"
     ]
    }
   ],
   "source": [
    "print (\"train_size\", len(Tr_word_list))\n",
    "print( \"val_size\", len(V_word_list))\n",
    "print( \"test_size\", len(Te_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_lengths, val_sent_lengths, test_sent_lengths = findSentLengths([Tr_word_list, V_word_list, Te_word_list])\n",
    "\n",
    "sentMax = max(train_sent_lengths + val_sent_lengths + test_sent_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'Negative':0, 'Positive':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SNP dataset to synchronize the dictionary IDs with our generated Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/pickles/train_and_test_data_sentences_snp_2class.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-41927bf9d70c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/pickles/train_and_test_data_sentences_snp_2class.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mW_train_snp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0md1_train_snp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0md2_train_snp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/pickles/train_and_test_data_sentences_snp_2class.pickle'"
     ]
    }
   ],
   "source": [
    "with open('../data/pickles/train_and_test_data_sentences_snp_2class.pickle', 'rb') as handle:    \n",
    "    \n",
    "    W_train_snp = pickle.load(handle)\n",
    "    d1_train_snp = pickle.load(handle)\n",
    "    d2_train_snp = pickle.load(handle)\n",
    "    Y_train_snp = pickle.load(handle)\n",
    "    Tr_word_list_snp = pickle.load(handle)\n",
    "    \n",
    "    W_test_snp = pickle.load(handle)\n",
    "    d1_test_snp = pickle.load(handle)\n",
    "    d2_test_snp = pickle.load(handle)\n",
    "    Y_test_snp = pickle.load(handle)\n",
    "    Te_word_list_snp = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "    word_vectors_snp = pickle.load(handle)\n",
    "    word_dict_snp = pickle.load(handle)\n",
    "    d1_dict_snp = pickle.load(handle)\n",
    "    d2_dict_snp = pickle.load(handle)\n",
    "    label_dict_snp = pickle.load(handle)\n",
    "    sentMax_snp = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tr_word_list_snp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-31a85a1412b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msent_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTr_word_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV_word_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTe_word_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTr_word_list_snp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTe_word_list_snp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_to_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tr_word_list_snp' is not defined"
     ]
    }
   ],
   "source": [
    "sent_list = sum([Tr_word_list, V_word_list, Te_word_list,Tr_word_list_snp,Te_word_list_snp], [])\n",
    "\n",
    "word_dict, word_to_id, id_to_word = word_mapping(sent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Word Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f58a5a6aa8b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"word dictonary length\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Word Embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadWordEmb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid_to_word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwefile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print( \"word dictonary length\", len(word_dict))\n",
    "\n",
    "# Word Embedding\n",
    "wv = readWordEmb(word_dict,id_to_word,word_to_id, wefile, embSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentMax_snp=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id_to_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8b607f30c75d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/integrated_entities.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_to_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentMax_snp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'id_to_word' is not defined"
     ]
    }
   ],
   "source": [
    "with open('data/integrated_entities.pickle', 'wb') as handle:\n",
    "    pickle.dump(id_to_word, handle)\n",
    "    pickle.dump(word_to_id, handle)\n",
    "    pickle.dump(sentMax_snp, handle)\n",
    "    pickle.dump(wv, handle)\n",
    "    pickle.dump(word_dict, handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_to_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3402e377e2db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Mapping Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mW_train\u001b[0m \u001b[1;33m=\u001b[0m   \u001b[0mmapWordToId\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTr_word_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_to_id' is not defined"
     ]
    }
   ],
   "source": [
    "# Mapping Train\n",
    "W_train =   mapWordToId(Tr_word_list, word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Lable Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_t = mapLabelToId(Tr_sent_lables, label_dict)\n",
    "Y_train = np.zeros((len(Y_t), len(label_dict)))\n",
    "for i in range(len(Y_t)):\n",
    "    Y_train[i][Y_t[i]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping Validation\n",
    "W_val =   mapWordToId(V_word_list, word_to_id)\n",
    "Y_t = mapLabelToId(V_sent_lables, label_dict)\n",
    "Y_val = np.zeros((len(Y_t), len(label_dict)))\n",
    "for i in range(len(Y_t)):\n",
    "    Y_val[i][Y_t[i]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Test\n",
    "W_test =   mapWordToId(Te_word_list, word_to_id)\n",
    "Y_t = mapLabelToId(Te_sent_lables, label_dict)\n",
    "Y_test = np.zeros((len(Y_t), len(label_dict)))\n",
    "for i in range(len(Y_t)):\n",
    "    Y_test[i][Y_t[i]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad Embdding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentMax=sentMax_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 3997\n",
      "test 1597\n"
     ]
    }
   ],
   "source": [
    "#padding\n",
    "W_train, W_val, W_test = paddData([W_train, W_val, W_test], sentMax) \n",
    "\n",
    "print (\"train\", len(W_train))\n",
    "print (\"test\", len(W_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3997, 91)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Integrated data as a Pickle file to be used for training the Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/my_corpus_integrated.pickle', 'wb') as handle:\n",
    "    pickle.dump(W_train, handle)    \n",
    "    pickle.dump(Y_train, handle)\n",
    "    pickle.dump(Tr_word_list, handle)\n",
    "    \n",
    "    pickle.dump(W_val, handle)\n",
    "    pickle.dump(Y_val, handle)\n",
    "    pickle.dump(V_word_list, handle)\n",
    "\n",
    "    pickle.dump(W_test, handle)\n",
    "    pickle.dump(Y_test, handle)\n",
    "    pickle.dump(Te_word_list, handle)\n",
    "\n",
    "    pickle.dump(wv, handle)\n",
    "    pickle.dump(word_dict, handle)\n",
    " \n",
    "    pickle.dump(label_dict, handle) \n",
    "    pickle.dump(sentMax, handle)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
